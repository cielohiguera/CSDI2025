{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0157f71-512c-4efb-8f1f-653de0b0afe1",
   "metadata": {},
   "source": [
    "# **Práctica 1: Sensado y análisis de audio**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f09ee7c-83b3-44bc-8522-7b7b4937ff5f",
   "metadata": {},
   "source": [
    "### Ciencia de Datos para Sensores Inteligentes/Tópicos Selectos en Sistemas Interactivos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f51d63a-b72e-4471-9b50-528828c68290",
   "metadata": {},
   "source": [
    "*Estudiante: Cielo Aholiva Higuera Gutiérrez*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c686c304-8672-4c43-b375-15e9e07268c3",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es implementar un sistema de registro de asistencia basado en el reconocimiento de audio, ofreciendo una alternativa moderna y eficiente al uso tradicional de listas en papel o códigos QR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de60bbc-ed74-4d72-9ca4-215f39b51f75",
   "metadata": {},
   "source": [
    "En el siguiente script se cargan los modelos entrenados utilizados para la clasificación de audios. El proceso incluye la grabación de audio en tiempo real, seguido de la predicción de la persona que habla, basándose en un conjunto de datos preexistente. Este enfoque permite realizar una predicción inmediata utilizando los datos capturados directamente desde el micrófono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4c38f173-f39c-437e-b5bb-0a39df81fd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyaudio --quiet\n",
    "!pip install librosa --quiet\n",
    "!pip install soundfile --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8326875c-e57c-42de-b7fc-dafb8924d5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerias\n",
    "import pyaudio\n",
    "import wave\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca563c9f-95ff-4911-8a80-0f2d31bb0609",
   "metadata": {},
   "source": [
    "### Metodo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ada038-559f-4519-aa28-fd5fd684b5cb",
   "metadata": {},
   "source": [
    "En el Método 1, se utilizaron grabaciones de audio que contienen la frase \"Confirmando mi asistencia\" para realizar el análisis y la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b1f50c6b-0155-4b57-8f2e-235f7143ff54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=2, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.RandomForestClassifier"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "with open('C:\\\\Users\\\\Cielo Aholiva\\\\Documents\\\\Ciencia de datos\\\\CDSI2025\\\\modelo_random_forest_method1.pkl', 'rb') as model_file:\n",
    "    model = joblib.load(model_file)\n",
    "print(model)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "a3a18565-2b4a-4fa2-b245-97a1b8c9301d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando...\n",
      "Grabación terminada.\n",
      "Predicción del audio grabado: AleM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documentos\\PHYTON\\Phyton programa\\1 CSharp\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Función para grabar audio desde el micrófono\n",
    "def grabar_audio(filename=\"audio_grabado.wav\", duration=5):\n",
    "    # Configuración de pyaudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Configuración de la grabación\n",
    "    channels = 1\n",
    "    rate = 16000  # Frecuencia de muestreo\n",
    "    frames_per_buffer = 1024\n",
    "    format = pyaudio.paInt16\n",
    "\n",
    "    # Iniciar la grabación\n",
    "    stream = p.open(format=format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=frames_per_buffer)\n",
    "\n",
    "    print(\"Grabando...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # Grabar durante la duración especificada\n",
    "    for i in range(0, int(rate / frames_per_buffer * duration)):\n",
    "        data = stream.read(frames_per_buffer)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Detener la grabación\n",
    "    print(\"Grabación terminada.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Guardar el archivo grabado\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "# Función para extraer características MFCC del archivo de audio\n",
    "def extraer_mfcc(filename=\"audio_grabado.wav\"):\n",
    "    # Cargar el audio con librosa\n",
    "    audio, sr = librosa.load(filename, sr=16000)\n",
    "\n",
    "    # Extraer los coeficientes MFCC\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "    # Promediar los MFCC a lo largo del tiempo\n",
    "    mfccs = np.mean(mfccs, axis=1)\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "# Función para cargar el modelo y hacer predicción\n",
    "def predecir_audio(model, mfccs):\n",
    "    # Convertir las características en un formato adecuado para el modelo\n",
    "    mfccs_reshaped = mfccs.reshape(1, -1)\n",
    "\n",
    "    # Hacer la predicción\n",
    "    prediccion = model.predict(mfccs_reshaped)\n",
    "    \n",
    "    return prediccion[0]\n",
    "\n",
    "\n",
    "# Grabar el audio\n",
    "grabar_audio(duration=3)  # Graba un audio de 3 segundos\n",
    "\n",
    "# Extraer las características MFCC del audio grabado\n",
    "mfccs = extraer_mfcc(\"audio_grabado.wav\")\n",
    "\n",
    "# Predecir el nombre de la persona a partir del audio grabado\n",
    "prediccion = predecir_audio(model, mfccs)\n",
    "\n",
    "# Mostrar el resultado de la predicción\n",
    "print(f\"Predicción del audio grabado: {prediccion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d2bc69-ab14-4139-99b4-b70c09a89eab",
   "metadata": {},
   "source": [
    "### Metodo 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e4aa70-5418-4666-9dfc-b3f938cea140",
   "metadata": {},
   "source": [
    "En el Método 2, se utilizaron grabaciones de audio que contienen la frase \"Asistencia de ${nombre}\" para realizar el análisis y la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c7b2e1b2-1057-4175-b63f-5279d708ceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=2, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.RandomForestClassifier"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "with open('C:\\\\Users\\\\Cielo Aholiva\\\\Documents\\\\Ciencia de datos\\\\CDSI2025\\\\modelo_random_forest_method2.pkl', 'rb') as model_file:\n",
    "    model = joblib.load(model_file)\n",
    "\n",
    "print(model)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "750e57dd-489b-4250-9e12-de0897294f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando...\n",
      "Grabación terminada.\n",
      "Predicción del audio grabado: Mariana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documentos\\PHYTON\\Phyton programa\\1 CSharp\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Función para grabar audio desde el micrófono\n",
    "def grabar_audio(filename=\"audio_grabado.wav\", duration=5):\n",
    "    # Configuración de pyaudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Configuración de la grabación\n",
    "    channels = 1\n",
    "    rate = 16000  # Frecuencia de muestreo\n",
    "    frames_per_buffer = 1024\n",
    "    format = pyaudio.paInt16\n",
    "\n",
    "    # Iniciar la grabación\n",
    "    stream = p.open(format=format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=frames_per_buffer)\n",
    "\n",
    "    print(\"Grabando...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # Grabar durante la duración especificada\n",
    "    for i in range(0, int(rate / frames_per_buffer * duration)):\n",
    "        data = stream.read(frames_per_buffer)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Detener la grabación\n",
    "    print(\"Grabación terminada.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Guardar el archivo grabado\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "# Función para extraer características MFCC del archivo de audio\n",
    "def extraer_mfcc(filename=\"audio_grabado.wav\"):\n",
    "    # Cargar el audio con librosa\n",
    "    audio, sr = librosa.load(filename, sr=16000)\n",
    "\n",
    "    # Extraer los coeficientes MFCC\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "    # Promediar los MFCC a lo largo del tiempo\n",
    "    mfccs = np.mean(mfccs, axis=1)\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "# Función para cargar el modelo y hacer predicción\n",
    "def predecir_audio(model, mfccs):\n",
    "    # Convertir las características en un formato adecuado para el modelo\n",
    "    mfccs_reshaped = mfccs.reshape(1, -1)\n",
    "\n",
    "    # Hacer la predicción\n",
    "    prediccion = model.predict(mfccs_reshaped)\n",
    "    \n",
    "    return prediccion[0]\n",
    "\n",
    "\n",
    "# Grabar el audio\n",
    "grabar_audio(duration=3)  # Graba un audio de 3 segundos\n",
    "\n",
    "# Extraer las características MFCC del audio grabado\n",
    "mfccs = extraer_mfcc(\"audio_grabado.wav\")\n",
    "\n",
    "# Predecir el nombre de la persona a partir del audio grabado\n",
    "prediccion = predecir_audio(model, mfccs)\n",
    "\n",
    "# Mostrar el resultado de la predicción\n",
    "print(f\"Predicción del audio grabado: {prediccion}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8acb6d-19b1-4c33-b47a-4acc39011b03",
   "metadata": {},
   "source": [
    "### Metodo 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0dcdbd-4dc4-4f3d-90fc-e2c78ff75e5a",
   "metadata": {},
   "source": [
    "En el Método 3, se utilizaron grabaciones de audio totalmente libres para realizar el análisis y la clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "e7cfd489-e37b-401d-8585-c832ddba657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=2, random_state=42)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.RandomForestClassifier"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "with open('C:\\\\Users\\\\Cielo Aholiva\\\\Documents\\\\Ciencia de datos\\\\CDSI2025\\\\modelo_random_forest_method3.pkl', 'rb') as model_file:\n",
    "    model = joblib.load(model_file)\n",
    "print(model)\n",
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b86c4425-0a18-422b-9209-13ab10829485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grabando...\n",
      "Grabación terminada.\n",
      "Predicción del audio grabado: Cielo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Documentos\\PHYTON\\Phyton programa\\1 CSharp\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Función para grabar audio desde el micrófono\n",
    "def grabar_audio(filename=\"audio_grabado.wav\", duration=5):\n",
    "    # Configuración de pyaudio\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    # Configuración de la grabación\n",
    "    channels = 1\n",
    "    rate = 16000  # Frecuencia de muestreo\n",
    "    frames_per_buffer = 1024\n",
    "    format = pyaudio.paInt16\n",
    "\n",
    "    # Iniciar la grabación\n",
    "    stream = p.open(format=format,\n",
    "                    channels=channels,\n",
    "                    rate=rate,\n",
    "                    input=True,\n",
    "                    frames_per_buffer=frames_per_buffer)\n",
    "\n",
    "    print(\"Grabando...\")\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    # Grabar durante la duración especificada\n",
    "    for i in range(0, int(rate / frames_per_buffer * duration)):\n",
    "        data = stream.read(frames_per_buffer)\n",
    "        frames.append(data)\n",
    "\n",
    "    # Detener la grabación\n",
    "    print(\"Grabación terminada.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "\n",
    "    # Guardar el archivo grabado\n",
    "    with wave.open(filename, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(p.get_sample_size(format))\n",
    "        wf.setframerate(rate)\n",
    "        wf.writeframes(b''.join(frames))\n",
    "\n",
    "# Función para extraer características MFCC del archivo de audio\n",
    "def extraer_mfcc(filename=\"audio_grabado.wav\"):\n",
    "    # Cargar el audio con librosa\n",
    "    audio, sr = librosa.load(filename, sr=16000)\n",
    "\n",
    "    # Extraer los coeficientes MFCC\n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)\n",
    "\n",
    "    # Promediar los MFCC a lo largo del tiempo\n",
    "    mfccs = np.mean(mfccs, axis=1)\n",
    "\n",
    "    return mfccs\n",
    "\n",
    "# Función para cargar el modelo y hacer predicción\n",
    "def predecir_audio(model, mfccs):\n",
    "    # Convertir las características en un formato adecuado para el modelo\n",
    "    mfccs_reshaped = mfccs.reshape(1, -1)\n",
    "\n",
    "    # Hacer la predicción\n",
    "    prediccion = model.predict(mfccs_reshaped)\n",
    "    \n",
    "    return prediccion[0]\n",
    "\n",
    "\n",
    "# Grabar el audio\n",
    "grabar_audio(duration=3)  # Graba un audio de 3 segundos\n",
    "\n",
    "# Extraer las características MFCC del audio grabado\n",
    "mfccs = extraer_mfcc(\"audio_grabado.wav\")\n",
    "\n",
    "# Predecir el nombre de la persona a partir del audio grabado\n",
    "prediccion = predecir_audio(model, mfccs)\n",
    "\n",
    "# Mostrar el resultado de la predicción\n",
    "print(f\"Predicción del audio grabado: {prediccion}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
